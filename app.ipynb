{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae66c3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 19:26:05.744 INFO    numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c82951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 22:24:45.294 INFO    numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from streamlit_cropper import st_cropper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0548e859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "# initialisation()\n",
    "img_file_buffer = st.camera_input(\"Take a picture\")\n",
    "labels = ['normal', 'mild', 'severe']\n",
    "if img_file_buffer:\n",
    "    bytes_data = img_file_buffer.getvalue()\n",
    "    img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)\n",
    "    'Photo taken'\n",
    "    @st.experimental_singleton\n",
    "    def dlib_objs():\n",
    "        fd = dlib.get_frontal_face_detector()\n",
    "        sp = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "        return fd, sp\n",
    "    fd, sp = dlib_objs()\n",
    "    gray, img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    faces = fd(img)\n",
    "    if faces:\n",
    "        st.balloons()\n",
    "        st.success('Its Working')\n",
    "        points = sp(gray, faces[0])\n",
    "        cx, cy = [i.x for i in points.parts()[36:42]], [i.y for i in points.parts()[36:42]]\n",
    "        x, y, radius = np.mean(cx, dtype = int), np.mean(cy, dtype = int), (max(cx) - min(cx)) // 2\n",
    "        mask = np.zeros(img.shape, dtype=\"uint8\")\n",
    "        mask = cv2.circle(mask, center = (x, y), radius = radius, thickness = -1, color = (1, 1, 1))\n",
    "        right_eye = (img * mask)[y - radius:y + radius, x - radius:x + radius]\n",
    "        cx, cy = [i.x for i in points.parts()[42:48]], [i.y for i in points.parts()[42:48]]\n",
    "        x, y, radius = np.mean(cx, dtype = int), np.mean(cy, dtype = int), (max(cx) - min(cx)) // 2\n",
    "        mask = np.zeros(img.shape, dtype=\"uint8\")\n",
    "        mask = cv2.circle(mask, center = (x, y), radius = radius, thickness = -1, color = (1, 1, 1))\n",
    "        left_eye = (img * mask)[y - radius:y + radius, x - radius:x + radius]\n",
    "#         st.image((cv2.cvtColor(img, cv2.COLOR_BGR2RGB) * mask)[y - radius:y + radius, x - radius:x + radius], width = 500)\n",
    "        col1, col2 = st.columns(2)\n",
    "        col1.header('Left Eye')\n",
    "        col1.image(left_eye, width = 300)\n",
    "        col2.header('Right Eye')\n",
    "        col2.image(right_eye, width = 300)\n",
    "        from tensorflow.keras.models import model_from_json\n",
    "        with open('model.json', 'r') as f:\n",
    "            js = f.read()\n",
    "        model = model_from_json(js)\n",
    "        model.load_weights('weights.h5')\n",
    "        preds = model.predict(np.array([cv2.resize(left_eye, (224, 224)), cv2.resize(right_eye, (224, 224))]))\n",
    "        col1.write('Result - ' + labels[np.argmax(preds[0])])\n",
    "        col2.write('Result - ' + labels[np.argmax(preds[1])])\n",
    "    else:\n",
    "        st.error('Where\\'s your face?')\n",
    "\n",
    "#     if img_file_buffer:\n",
    "#         img = Image.open(img_file_buffer)\n",
    "#         cropped_img = st_cropper(img)\n",
    "#     st.image(cropped_img, width = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bff65db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "streamlit-cropper\n",
    "Pillow\n",
    "dlib-bin\n",
    "opencv-python-headless\n",
    "tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60832e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d4555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
